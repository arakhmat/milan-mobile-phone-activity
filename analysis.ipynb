{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import load_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geojsons = load_utils.load_geojsons() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = '2013-11-01'\n",
    "n_days     = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces_df, countries_df = load_utils.load_provinces_and_countries(start_date, n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry\n",
    "from phonenumbers import COUNTRY_CODE_TO_REGION_CODE\n",
    "\n",
    "def create_code_to_country(countries_df):\n",
    "    code_to_country = {}\n",
    "    country_codes = set(countries_df['countrycode'])\n",
    "    for country_code in country_codes:\n",
    "        \n",
    "        if country_code == 0:\n",
    "            code_to_country[country_code] = 'Domestic'\n",
    "        else:\n",
    "            try:\n",
    "                region_codes = COUNTRY_CODE_TO_REGION_CODE[country_code]\n",
    "                for region_code in region_codes:\n",
    "                    country_name = pycountry.countries.get(alpha_2=region_code).name\n",
    "                    if country_code not in code_to_country:\n",
    "                        code_to_country[country_code]  = [country_name]\n",
    "                    else:\n",
    "                        code_to_country[country_code] += [country_name]\n",
    "            except KeyError:\n",
    "                pass\n",
    "    return code_to_country\n",
    "\n",
    "code_to_country = create_code_to_country(countries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = sorted(list(set(provinces_df['provinceName'])))\n",
    "\n",
    "countries = []\n",
    "for value in code_to_country.values():\n",
    "    for country in value:\n",
    "        countries.append(country) \n",
    "countries = sorted(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "province_columns = list(provinces_df.columns[2:])\n",
    "country_columns  = list(countries_df.columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_columns_names(provinces_df, countries_df,\n",
    "                         provinces, countries):\n",
    "    \n",
    "    \n",
    "    def create_column_names(columns, regions):\n",
    "        column_names = []\n",
    "        for column in columns:\n",
    "            for region in regions:\n",
    "                column_names.append('{}_{}'.format(column, region))\n",
    "        return column_names\n",
    "           \n",
    "    column_names  = create_column_names(provinces_df.columns[2:], provinces)\n",
    "    column_names += create_column_names(countries_df.columns[2:], countries)\n",
    "    return column_names\n",
    "\n",
    "column_names = create_columns_names(provinces_df, countries_df, provinces, countries)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cells     = 10000\n",
    "n_hours     = 24 * n_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_indices = pd.concat([pd.DataFrame(np.repeat(provinces_df.index.drop_duplicates().values, n_cells), columns=['datetime'])]).reset_index(drop=True)\n",
    "cell_indices = pd.concat([pd.DataFrame(np.arange(n_cells), columns=['CellID'])] * n_hours).reset_index(drop=True)\n",
    "df_index     = pd.MultiIndex.from_tuples(list(zip(list(time_indices['datetime']), list(cell_indices['CellID']))), names=['datetime', 'CellID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keep it as an array for now in order to populate it faster\n",
    "df = np.zeros((n_hours*n_cells, len(column_names)))\n",
    "row_indices_map    = {key: value for value, key in enumerate(df_index.values)}\n",
    "column_indices_map = {key: value for value, key in enumerate(column_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import progressbar\n",
    "def populate_df(df, row_indices_map, column_indices_map,\n",
    "                regions_df, code_to_country=None):\n",
    "    \n",
    "    if 'provinceName' in regions_df:\n",
    "        source = 'provinces_df'\n",
    "    else:\n",
    "        source = 'countries_df'\n",
    "    \n",
    "    print('Populating with data from \"{}\"'.format(source))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    bar = progressbar.ProgressBar(max_value=len(regions_df))\n",
    "    column_names = regions_df.columns[2:]\n",
    "    \n",
    "    for i, row in enumerate(regions_df.to_records()):\n",
    "        try:\n",
    "            row = list(row)\n",
    "            time_index, cell_index, region = row[:3]\n",
    "            if 'countrycode' in regions_df:\n",
    "                regions = code_to_country[region]\n",
    "            else:\n",
    "                regions = [region]\n",
    "            values = row[3:]\n",
    "            \n",
    "            for column_name, value in zip(column_names, values):\n",
    "                for region in regions:\n",
    "                    df_column_name = '{}_{}'.format(column_name, region)\n",
    "                    row_index    = row_indices_map[(time_index, cell_index)]\n",
    "                    column_index = column_indices_map[df_column_name]\n",
    "                    df[row_index, column_index] = value\n",
    "                \n",
    "        except KeyError as e:\n",
    "            pass\n",
    "        bar.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "populate_df(df, row_indices_map, column_indices_map, provinces_df)\n",
    "populate_df(df, row_indices_map, column_indices_map, countries_df, code_to_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(df, columns=column_names, index=df_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.palettes import Viridis256 as palette\n",
    "from bokeh.models import LinearColorMapper as mapper\n",
    "\n",
    "color_mapper = mapper(palette=palette, low=0, high=255)\n",
    "TOOLS = \"pan,wheel_zoom,reset,hover,save\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "from bokeh.models import (\n",
    " GMapPlot, GMapOptions, Patches, Range1d,\n",
    ")\n",
    "\n",
    "def grid_plot(source, title, color_mapper, tools):\n",
    "    p = figure(\n",
    "       title=title, tools=tools,\n",
    "       x_axis_location=None, y_axis_location=None\n",
    "    )\n",
    "    p.grid.grid_line_color = None\n",
    "\n",
    "    p.patches('lon', 'lat', source=source,\n",
    "             fill_color={'field': 'calls', 'transform': color_mapper},\n",
    "             fill_alpha=0.5, line_color=None, line_width=1)\n",
    "\n",
    "    hover = p.select_one(HoverTool)\n",
    "    hover.point_policy = \"follow_mouse\"\n",
    "    hover.tooltips = [\n",
    "       (\"Name\", \"@names\"),\n",
    "       (\"Calls)\", \"@calls\"),\n",
    "       (\"(Lat, Lon)\", \"(@center_lat, @center_lon)\"),\n",
    "    ]\n",
    "    \n",
    "    return p\n",
    "\n",
    "def gmap_plot(source, title, color_mapper, center_coors, api_key):\n",
    "    map_options = GMapOptions(lat=center_coors['lat'], lng=center_coors['lon'], \n",
    "                              map_type=\"hybrid\", zoom=11, scale_control=True)\n",
    "    p = GMapPlot(x_range=Range1d(), y_range=Range1d(), map_options=map_options)\n",
    "    p.grid.grid_line_color = None\n",
    "    p.title.text = title\n",
    "    p.api_key = api_key\n",
    "\n",
    "    patches = Patches(xs='lon', ys='lat',\n",
    "                 fill_color={'field': 'calls', 'transform': color_mapper},\n",
    "                 fill_alpha=0.5, line_color=None, line_width=1)\n",
    "    p.add_glyph(source, patches)\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use bokeh.io.export_png you need selenium (\"conda install -c bokeh selenium\" or \"pip install selenium\")\n",
    "# pip install pillow==4.0.0\n",
    "# To use bokeh.io.export_png you need pillow (\"conda install pillow\" or \"pip install pillow\")\n",
    "# PhantomJS is not present in PATH. Try \"conda install phantomjs\n",
    "\n",
    "from bokeh.io import show, output_file, export_png\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.layouts import column\n",
    "\n",
    "def plot_milan(df, geojsons, color_mapper, periods=1, gmap=True):\n",
    "    output_file(\"milan.html\")\n",
    "\n",
    "    lon = [[coors[0] for coors in cell[\"geometry\"][\"coordinates\"][0]] for cell in geojsons['grid']['features']]\n",
    "    lat = [[coors[1] for coors in cell[\"geometry\"][\"coordinates\"][0]] for cell in geojsons['grid']['features']]\n",
    "    names = [cell[\"id\"] for cell in geojsons['grid']['features']]\n",
    "\n",
    "    date_range = pd.date_range(df.index[0][0], periods=periods, freq='1H')\n",
    "\n",
    "    plot_data = {}\n",
    "    for i, date in enumerate(date_range):\n",
    "\n",
    "        hour_df = df.loc[pd.IndexSlice[str(date)]]\n",
    "\n",
    "        traffic_per_cell = hour_df.sum(axis=1)\n",
    "        traffic_per_cell = np.log(traffic_per_cell) # Smooth the data\n",
    "        plot_data[date] = traffic_per_cell\n",
    "\n",
    "    maximum = np.array(list(plot_data.values())).max()\n",
    "\n",
    "    plots = []\n",
    "    bar = progressbar.ProgressBar(max_value=len(plot_data))\n",
    "    for i, (date, traffic_per_cell) in enumerate(plot_data.items()):\n",
    "\n",
    "        calls = traffic_per_cell.copy()\n",
    "        calls /= maximum\n",
    "        calls *= 255\n",
    "        calls = calls.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        calls = calls.astype(int)\n",
    "\n",
    "        source = ColumnDataSource(data=dict(\n",
    "            lon=lon,\n",
    "            lat=lat,\n",
    "            names=names,\n",
    "            calls=calls,\n",
    "            center_lon=[np.mean(x) for x in lon],\n",
    "            center_lat=[np.mean(x) for x in lat],\n",
    "        ))\n",
    "        \n",
    "        title = 'Cell Phone Usage in the City of Milan on {} at {}'.format(\n",
    "                    date.strftime('%Y-%m-%d'), date.strftime('%H-%M-%S'))\n",
    "\n",
    "        if not gmap:\n",
    "            p = grid_plot(source, title, color_mapper, TOOLS)\n",
    "        else:\n",
    "            center_coors = {\n",
    "                'lat': np.asarray(lat).mean(),\n",
    "                'lon': np.asarray(lon).mean()}\n",
    "            p = gmap_plot(source, title, color_mapper, center_coors, config.gmaps_api_key)\n",
    "            \n",
    "#         export_png(p, filename='{}.png'.format(str(date)))\n",
    "\n",
    "        plots.append(p)\n",
    "        bar.update(i)\n",
    "        \n",
    "    return plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = plot_milan(df, geojsons, color_mapper, n_hours)\n",
    "show(column(*plots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the provinces whose names are not matching between DataFrame and geojson\n",
    "replacement_dict = {\n",
    "    'MASSA CARRARA': 'MASSA-CARRARA'\n",
    "}\n",
    "\n",
    "for province in geojsons['provinces']['features']:\n",
    "    province_name = province['properties']['PROVINCIA'].upper()\n",
    "    if province_name in replacement_dict:\n",
    "        province['properties']['PROVINCIA'] = replacement_dict[province_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_italy(df, geojsons, color_mapper):\n",
    "    output_file(\"italy.html\")\n",
    "\n",
    "    lon = [[coors[0] for coors in province[\"geometry\"][\"coordinates\"][0][0]] for province in geojsons['provinces']['features']]\n",
    "    lat = [[coors[1] for coors in province[\"geometry\"][\"coordinates\"][0][0]] for province in  geojsons['provinces']['features']]\n",
    "    names = [province[\"properties\"][\"PROVINCIA\"].upper() for province in geojsons['provinces']['features']]\n",
    "    calls = [df[df.filter(like=province).columns].sum().sum() for province in names]\n",
    "    \n",
    "    calls = np.log(calls) # Smoothen\n",
    "    calls /= np.asarray(calls).max() # Normalize\n",
    "    calls *= 255 # Scale to pallete\n",
    "    \n",
    "    source = ColumnDataSource(data=dict(\n",
    "       lon=lon,\n",
    "       lat=lat,\n",
    "       names=names,\n",
    "       calls=calls,\n",
    "       center_lon=[np.mean(x) for x in lon],\n",
    "       center_lat=[np.mean(x) for x in lat],\n",
    "    ))\n",
    "\n",
    "    p = figure(\n",
    "       title=\"Italian Provinces by Number of Calls with Milan\", tools=TOOLS,\n",
    "       x_axis_location=None, y_axis_location=None\n",
    "    )\n",
    "    p.grid.grid_line_color = None\n",
    "\n",
    "    p.patches('lon', 'lat', source=source,\n",
    "             fill_color={'field': 'calls', 'transform': color_mapper},\n",
    "             fill_alpha=0.7, line_color=\"white\", line_width=0.5)\n",
    "\n",
    "    hover = p.select_one(HoverTool)\n",
    "    hover.point_policy = \"follow_mouse\"\n",
    "    hover.tooltips = [\n",
    "       (\"Name\", \"@names\"),\n",
    "       (\"Calls)\", \"@calls\"),\n",
    "       (\"(Lat, Lon)\", \"(@center_lat, @center_lon)\"),\n",
    "    ]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_italy = plot_italy(df, geojsons, color_mapper)\n",
    "show(p_italy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_world(df, geojsons, color_mapper):\n",
    "    output_file(\"world.html\")\n",
    "    \n",
    "    lon = []\n",
    "    lat = []\n",
    "    names = []\n",
    "    calls = []\n",
    "    \n",
    "    for country in geojsons['countries']['features']:  \n",
    "        if country[\"id\"] == '-99': # Norther Cyprus\n",
    "            country[\"id\"] = \"CYP\"\n",
    "        elif country[\"id\"] == 'CS-KM': # Kosovo\n",
    "            country[\"id\"] = \"SRB\"\n",
    "        name = pycountry.countries.get(alpha_3=country[\"id\"]).name\n",
    "        \n",
    "        if len(df.filter(like=name).columns) == 0:\n",
    "            print(name)\n",
    "\n",
    "        geometry = country[\"geometry\"]\n",
    "        if geometry['type'] == 'Polygon':\n",
    "            country_borders = [geometry[\"coordinates\"][0]]\n",
    "\n",
    "        elif geometry['type'] == 'MultiPolygon':\n",
    "            country_borders = []\n",
    "            for polygon in geometry[\"coordinates\"]:\n",
    "                country_borders += polygon\n",
    "        else:\n",
    "            raise ValueError('Unknown type of geojson')\n",
    "\n",
    "        for polygon in country_borders:\n",
    "            lon.append([])\n",
    "            lat.append([])\n",
    "            names.append(name)\n",
    "            calls.append(df[df.filter(like=name).columns].sum().sum())\n",
    "            for coors in polygon:\n",
    "                lon[-1].append(coors[0])\n",
    "                lat[-1].append(coors[1])\n",
    "                \n",
    "    calls = np.log(calls) # Smoothen\n",
    "    calls /= np.asarray(calls).max() # Normalize\n",
    "    calls *= 255 # Scale to pallete\n",
    "    calls = calls.tolist()\n",
    "\n",
    "    source = ColumnDataSource(data=dict(\n",
    "       lon=lon,\n",
    "       lat=lat,\n",
    "       names=names,\n",
    "       calls=calls,\n",
    "       center_lon=[np.mean(x) for x in lon],\n",
    "       center_lat=[np.mean(x) for x in lat],\n",
    "    ))\n",
    "\n",
    "    p = figure(\n",
    "       title=\"Countries by Number of Calls with Milan\", tools=TOOLS,\n",
    "       x_axis_location=None, y_axis_location=None,\n",
    "       plot_width=1500, plot_height=600\n",
    "    )\n",
    "#     p.grid.grid_line_color = None\n",
    "\n",
    "    p.patches('lon', 'lat', source=source,\n",
    "             fill_color={'field': 'calls', 'transform': color_mapper},\n",
    "             fill_alpha=0.7, line_color=\"white\", line_width=0.5)\n",
    "\n",
    "    hover = p.select_one(HoverTool)\n",
    "    hover.point_policy = \"follow_mouse\"\n",
    "    hover.tooltips = [\n",
    "       (\"Name\", \"@names\"),\n",
    "       (\"Calls)\", \"@calls\"),\n",
    "       (\"(Lat, Lon)\", \"(@center_lat, @center_lon)\"),\n",
    "    ]\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_world = plot_world(df, geojsons, color_mapper)\n",
    "show(p_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOMALY DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy df to data in order to keep the data untouched\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "data -= data.mean()\n",
    "data /= data.std()\n",
    "data = data.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Random Anomalies\n",
    "def add_anomalies(data, percentage=0.01):\n",
    "    n_anomalies = int(percentage * len(data)) # 1% of data\n",
    "    data = data.append(pd.DataFrame(np.zeros((n_anomalies, data.shape[1])), columns=data.columns))\n",
    "    for index in range(len(data) - n_anomalies, len(data)):\n",
    "        # Random connections\n",
    "        n_random_indices = np.random.randint(4, 10)\n",
    "        random_indices = np.random.randint(0, data.shape[1],  n_random_indices)\n",
    "        data.iloc[index, random_indices] = np.random.uniform(-1.0, 1.0, size=n_random_indices)\n",
    "    return data, n_anomalies\n",
    "\n",
    "data, n_anomalies = add_anomalies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add CellIDs\n",
    "data['CellID'] = 0\n",
    "data.loc[data.index.values[:-n_anomalies], 'CellID'] = np.array([cell_index for _, cell_index in df.index.values])\n",
    "data.loc[data.index.values[-n_anomalies:], 'CellID'] = np.random.randint(0, n_cells, n_anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add Labels\n",
    "data['anomaly'] = 0\n",
    "data.loc[data.index.values[-n_anomalies:], 'anomaly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batches(data, batch_size=32678):\n",
    "    \n",
    "    n_batches = len(data)//batch_size\n",
    "    print('Data consists of {} batches'.format(n_batches))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    bar = progressbar.ProgressBar(max_value=n_batches)\n",
    "    for batch_index in range(0, n_batches):\n",
    "        \n",
    "        bar.update(batch_index)\n",
    "        \n",
    "        batch = data.iloc[batch_index*batch_size:(batch_index+1)*batch_size]\n",
    "        \n",
    "        one_hot = np.zeros((batch_size, n_cells))\n",
    "        for i in range(len(one_hot)):\n",
    "            one_hot[i, batch['CellID'].values[i]] = 1\n",
    "        one_hot = pd.DataFrame(one_hot, columns=['CellID_'+str(i) for i in range(n_cells)], index=batch.index)\n",
    "        batch = batch.join(one_hot)\n",
    "        \n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "print('Training the Model')\n",
    "for batch in batches(train_data):\n",
    "    clf.fit(batch.drop(['CellID', 'anomaly'], axis=1), batch['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Evaluating the Model')\n",
    "y_true = np.array([])\n",
    "y_pred = np.array([])\n",
    "for batch in batches(test_data, batch_size=4096):\n",
    "    y_true = np.append(y_true, batch['anomaly'].values)\n",
    "    y_pred = np.append(y_pred, clf.predict(batch.drop(['CellID', 'anomaly'], axis=1)))\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.where(y_pred == 1)\n",
    "index = indices[0][0]\n",
    "anomaly_example = test_data.iloc[index]\n",
    "cell_id = int(anomaly_example['CellID'])\n",
    "print(anomaly_example[anomaly_example > 0], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_examples = data.iloc[:-n_anomalies][data.iloc[:-n_anomalies]['CellID'] == cell_id]\n",
    "for i, (index, example) in enumerate(normal_examples.iterrows()):\n",
    "    print(example[example > 0], end='\\n\\n')\n",
    "    \n",
    "    if i == 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
